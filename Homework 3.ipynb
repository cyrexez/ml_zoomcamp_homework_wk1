{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e10fb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-12 22:48:13--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80876 (79K) [text/plain]\n",
      "Saving to: 'course_lead_scoring.csv'\n",
      "\n",
      "course_lead_scoring 100%[===================>]  78.98K   397KB/s    in 0.2s    \n",
      "\n",
      "2025-10-12 22:48:15 (397 KB/s) - 'course_lead_scoring.csv' saved [80876/80876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3c7259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b6ca23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('course_lead_scoring.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae04a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_source                 128\n",
      "industry                    134\n",
      "number_of_courses_viewed      0\n",
      "annual_income               181\n",
      "employment_status           100\n",
      "location                     63\n",
      "interaction_count             0\n",
      "lead_score                    0\n",
      "converted                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "num_cols = df.select_dtypes(exclude='object').columns\n",
    "\n",
    "# Replace missing values\n",
    "df[cat_cols] = df[cat_cols].fillna('NA')\n",
    "df[num_cols] = df[num_cols].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "583c1985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retail           203\n",
       "finance          200\n",
       "other            198\n",
       "healthcare       187\n",
       "education        187\n",
       "technology       179\n",
       "manufacturing    174\n",
       "NA               134\n",
       "Name: industry, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3196a706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction_count and lead_score: 0.0099\n",
      "number_of_courses_viewed and lead_score: -0.0049\n",
      "number_of_courses_viewed and interaction_count: -0.0236\n",
      "annual_income and interaction_count: 0.0270\n"
     ]
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "\n",
    "pairs = [\n",
    "    ('interaction_count', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'interaction_count'),\n",
    "    ('annual_income', 'interaction_count'),\n",
    "]\n",
    "\n",
    "for a, b in pairs:\n",
    "    print(f\"{a} and {b}: {corr.loc[a, b]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1faa1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2c056fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset sizes: train, val, test = 877 292 293\n"
     ]
    }
   ],
   "source": [
    "y = df['converted']\n",
    "X = df.drop('converted', axis=1)\n",
    "\n",
    "# first split: train (60%) vs temp (40%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "# split temp into val (20%) and test (20%) => split temp equally\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(\"\\nDataset sizes: train, val, test =\", len(X_train), len(X_val), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "236b31f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q3: Mutual information scores (train set) for categorical variables (rounded to 2 decimals):\n",
      "  lead_source: 0.03\n",
      "  industry: 0.01\n",
      "  employment_status: 0.01\n",
      "  location: 0.0\n",
      "  -> variable with biggest MI: lead_source\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- Q3: mutual information (on training set) for categorical variables ----------\n",
    "# We'll compute MI for categorical variables only (train set).\n",
    "# Convert training categorical columns to codes for mutual_info_classif\n",
    "cat_cols_train = [c for c in cat_cols if c in X_train.columns]\n",
    "\n",
    "# For MI, we need numeric arrays. Use pandas factorize for each categorical column.\n",
    "mi_scores = {}\n",
    "for col in cat_cols_train:\n",
    "    # factorize\n",
    "    codes, uniques = pd.factorize(X_train[col])\n",
    "    mi = mutual_info_classif(codes.reshape(-1,1), y_train, discrete_features=True, random_state=42)\n",
    "    mi_scores[col] = float(mi[0])\n",
    "\n",
    "# Round scores to 2 decimals and show sorted\n",
    "mi_sorted = sorted(mi_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nQ3: Mutual information scores (train set) for categorical variables (rounded to 2 decimals):\")\n",
    "for col, score in mi_sorted:\n",
    "    print(f\"  {col}: {round(score,2)}\")\n",
    "\n",
    "top_mi_var = mi_sorted[0][0] if mi_sorted else None\n",
    "print(\"  -> variable with biggest MI:\", top_mi_var)\n",
    "\n",
    "# ---------- Utility: One-hot encode categorical columns for model training ----------\n",
    "def one_hot_encode_fit_transform(X_train, X_other, categorical_columns):\n",
    "    \"\"\"\n",
    "    Fit OneHotEncoder on X_train[categorical_columns] then transform X_train and X_other.\n",
    "    Returns (X_train_transformed_df, X_other_transformed_df, ohe)\n",
    "    \"\"\"\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    X_train_cat = ohe.fit_transform(X_train[categorical_columns])\n",
    "    X_other_cat = ohe.transform(X_other[categorical_columns])\n",
    "\n",
    "    # build DataFrames for cat features\n",
    "    cat_feature_names = ohe.get_feature_names_out(categorical_columns)\n",
    "\n",
    "    X_train_cat_df = pd.DataFrame(X_train_cat, columns=cat_feature_names, index=X_train.index)\n",
    "    X_other_cat_df = pd.DataFrame(X_other_cat, columns=cat_feature_names, index=X_other.index)\n",
    "\n",
    "    # drop original categorical columns from X and concat encoded\n",
    "    X_train_num = X_train.drop(columns=categorical_columns)\n",
    "    X_other_num = X_other.drop(columns=categorical_columns)\n",
    "\n",
    "    X_train_final = pd.concat([X_train_num.reset_index(drop=True), X_train_cat_df.reset_index(drop=True)], axis=1)\n",
    "    X_other_final = pd.concat([X_other_num.reset_index(drop=True), X_other_cat_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    return X_train_final, X_other_final, ohe\n",
    "\n",
    "# Prepare feature matrix using one-hot encoding of categorical features\n",
    "categorical_columns_for_model = [c for c in cat_cols if c in X_train.columns]  # use all categorical columns in data\n",
    "X_train_enc, X_val_enc, ohe = one_hot_encode_fit_transform(X_train, X_val, categorical_columns_for_model)\n",
    "\n",
    "# For testing later, also transform test set\n",
    "X_train_enc_full = X_train_enc.copy()\n",
    "X_test_enc = pd.concat([X_test.drop(columns=categorical_columns_for_model).reset_index(drop=True),\n",
    "                        pd.DataFrame(ohe.transform(X_test[categorical_columns_for_model]), columns=ohe.get_feature_names_out(categorical_columns_for_model)).reset_index(drop=True)],\n",
    "                       axis=1)\n",
    "\n",
    "# Ensure numeric columns are floats\n",
    "X_train_enc = X_train_enc.astype(float)\n",
    "X_val_enc = X_val_enc.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84137d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q4: Validation accuracy = 0.6815 -> rounded to 2 decimals: 0.68\n"
     ]
    }
   ],
   "source": [
    "# ---------- Q4: logistic regression training and val accuracy ----------\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_enc, y_train)\n",
    "y_val_pred = model.predict(X_val_enc)\n",
    "acc_val = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"\\nQ4: Validation accuracy = {acc_val:.4f} -> rounded to 2 decimals: {round(acc_val,2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dae0847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5: Removing industry -> val acc: 0.6884; diff baseline-wo = -0.006849\n",
      "Q5: Removing employment_status -> val acc: 0.6815; diff baseline-wo = 0.000000\n",
      "Q5: Removing lead_score -> val acc: 0.6747; diff baseline-wo = 0.006849\n",
      "  -> feature with smallest absolute difference: employment_status\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- Q5: feature-elimination experiment ----------\n",
    "# We'll consider the following features to possibly drop:\n",
    "# For this question they asked about 'industry', 'employment_status', 'lead_score'\n",
    "features_to_test = ['industry', 'employment_status', 'lead_score']\n",
    "\n",
    "# Build baseline model using the same pipeline (we already have baseline acc_val)\n",
    "baseline_acc = acc_val\n",
    "\n",
    "# For this experiment we want to remove each feature from the dataset (both numeric or categorical)\n",
    "differences = {}\n",
    "for feature in features_to_test:\n",
    "    # Create copies of X_train and X_val with the feature removed\n",
    "    X_train_tmp = X_train.copy()\n",
    "    X_val_tmp = X_val.copy()\n",
    "    if feature in X_train_tmp.columns:\n",
    "        X_train_tmp = X_train_tmp.drop(columns=[feature])\n",
    "        X_val_tmp = X_val_tmp.drop(columns=[feature])\n",
    "    else:\n",
    "        # if not present, skip\n",
    "        print(f\"Feature {feature} not found in X_train columns; skipping\")\n",
    "        continue\n",
    "\n",
    "    # Re-encode after drop\n",
    "    cat_cols_tmp = [c for c in categorical_columns_for_model if c in X_train_tmp.columns]\n",
    "    X_train_tmp_enc, X_val_tmp_enc, ohe_tmp = one_hot_encode_fit_transform(X_train_tmp, X_val_tmp, cat_cols_tmp)\n",
    "\n",
    "    # Train model with same params\n",
    "    model_tmp = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_tmp.fit(X_train_tmp_enc, y_train)\n",
    "    y_val_tmp_pred = model_tmp.predict(X_val_tmp_enc)\n",
    "    acc_tmp = accuracy_score(y_val, y_val_tmp_pred)\n",
    "    diff = baseline_acc - acc_tmp\n",
    "    differences[feature] = diff\n",
    "    print(f\"Q5: Removing {feature} -> val acc: {acc_tmp:.4f}; diff baseline-wo = {diff:.6f}\")\n",
    "\n",
    "# Which feature has smallest difference?\n",
    "smallest_feature = min(differences.items(), key=lambda x: abs(x[1]))[0]\n",
    "print(\"  -> feature with smallest absolute difference:\", smallest_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9871e71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6: C=0.01 -> val accuracy = 0.688\n",
      "Q6: C=0.1 -> val accuracy = 0.682\n",
      "Q6: C=1 -> val accuracy = 0.682\n",
      "Q6: C=10 -> val accuracy = 0.682\n",
      "Q6: C=100 -> val accuracy = 0.682\n",
      "  -> Best C: 0.01\n"
     ]
    }
   ],
   "source": [
    "# ---------- Q6: try different C values ----------\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "results_C = {}\n",
    "for C in C_values:\n",
    "    model_c = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model_c.fit(X_train_enc, y_train)\n",
    "    y_val_c = model_c.predict(X_val_enc)\n",
    "    acc_c = accuracy_score(y_val, y_val_c)\n",
    "    results_C[C] = acc_c\n",
    "    print(f\"Q6: C={C} -> val accuracy = {acc_c:.3f}\")\n",
    "\n",
    "# Find best C (if tie, smallest C as instruction)\n",
    "best_C = min([C for C, acc in results_C.items() if acc == max(results_C.values())])\n",
    "print(\"  -> Best C:\", best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc9803f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
